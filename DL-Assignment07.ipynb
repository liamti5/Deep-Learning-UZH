{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7: Transfer Learning\n",
    "\n",
    "\n",
    "The goal of this exercise is to learn how to use pre-trained networks in transfer learning tasks.\n",
    "We will make use of networks trained on ImageNet, and apply them to related problems, i.e., the classification of $6$ categories such as buildings, forests, glaciers, mountains, seas, and streets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "For this exercise we use the  [Intel Image Classification](https://www.kaggle.com/datasets/puneet6060/intel-image-classification) dataset that can be downloaded from the official website [here]({https://www.kaggle.com/datasets/puneet6060/intel-image-classification}).\n",
    "The dataset contains $25000$ color images of pixels size $150\\times 150$ in $6$ classes: buildings, forests, glaciers, mountains, seas, and streets. We will be using only $17000$ of those images where $14000$ are for training and $3000$ for test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 0: Download and check if dataset is downloaded correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the dataset by running the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library for downloading datasets from Kaggle\n",
    "! pip install opendatasets --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Write kaggle.json file\n",
    "with open('kaggle.json', 'w') as file:\n",
    "    json.dump({'username': '', 'key': ''}, file)\n",
    "\n",
    "import opendatasets\n",
    "opendatasets.download('https://www.kaggle.com/puneet6060/intel-image-classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the cell above, just verify that the dataset has been downloaded correctly by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def count_images(directory):\n",
    "    \"\"\"Count the number of image files in the given directory and its subdirectories.\"\"\"\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        count += sum(1 for file in files if file.endswith(('.jpg', '.jpeg', '.png')))\n",
    "    return count\n",
    "\n",
    "def validate_dataset(base_path):\n",
    "    \"\"\"Validate the structure and the count of images in the dataset.\"\"\"\n",
    "    expected_structure = {\n",
    "        'seg_train': 14034,\n",
    "        'seg_test': 3000\n",
    "    }\n",
    "\n",
    "    errors = []\n",
    "\n",
    "    # Check if base directory exists\n",
    "    if not os.path.exists(base_path):\n",
    "        errors.append(f\"Base directory {base_path} does not exist.\")\n",
    "        return errors\n",
    "\n",
    "    # Check each subdirectory and count images\n",
    "    for folder, expected_count in expected_structure.items():\n",
    "        folder_path = os.path.join(base_path, folder)\n",
    "        if not os.path.exists(folder_path):\n",
    "            errors.append(f\"Expected folder {folder_path} does not exist.\")\n",
    "        else:\n",
    "            image_count = count_images(folder_path)\n",
    "            if image_count != expected_count:\n",
    "                errors.append(f\"Folder {folder} has {image_count} images, expected {expected_count}.\")\n",
    "\n",
    "    return errors\n",
    "\n",
    "# Specify the path to the base of the dataset\n",
    "base_dataset_path = \"intel-image-classification/\" #Change if you downloaded manually to some other path\n",
    "\n",
    "# Perform the validation\n",
    "validation_errors = validate_dataset(base_dataset_path)\n",
    "\n",
    "if not validation_errors:\n",
    "    print(\"Dataset is validated successfully. Test Passed\")\n",
    "else:\n",
    "    print(\"Errors found in dataset validation:\")\n",
    "    for error in validation_errors:\n",
    "        print(error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Data Transformation\n",
    "\n",
    "We need to instantiate a proper `torchvision.transform` instance to create the same input structure as used for training our network.\n",
    "We need to combine 4 transforms. The different transforms in Pytorch are available here: https://pytorch.org/vision/0.9/transforms.html.\n",
    "\n",
    "1. We need to resize the image such that the shorter side has size 256.\n",
    "2. We need to take the center crop of size $224\\times224$ from the image.\n",
    "3. We need to convert the image into a tensor (including pixel values scaling)\n",
    "4. We need to normalize the pixel values with mean $(0.485, 0.456, 0.406)$ and standard deviation $(0.229, 0.224, 0.225)$.\n",
    "\n",
    "Since we will use networks pre-trained on ImageNet, we need to perform the exact same transform as used for ImageNet testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "imagenet_transform = ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Dataset Loading\n",
    "\n",
    "We here use the [ImageFolder](https://pytorch.org/vision/main/generated/torchvision.datasets.ImageFolder.html) class from pytorch to load our training and test set respectively. \n",
    "\n",
    "This task consists of two parts:\n",
    "\n",
    "1. Create two datasets, one for the training set, one for the test set. Use the transform defined above.\n",
    "2. Once the datasets are created, create two data loaders, one for training set, one for test set. Use a proper value of the batch-size $B = 256$. Make sure the trainloader shuffle is set to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "#Path to your training and test data (If different, change the path accordingly)\n",
    "train_dir = './intel-image-classification/seg_train/seg_train/'\n",
    "test_dir = './intel-image-classification/seg_test/seg_test/'\n",
    "\n",
    "trainset = ImageFolder(\n",
    "  ...\n",
    ")\n",
    "\n",
    "testset = ImageFolder(\n",
    "  ...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = ...\n",
    "trainloader = torch.utils.data.DataLoader(...)\n",
    "testloader = torch.utils.data.DataLoader(...)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Data Size and Types\n",
    "\n",
    "We check that all input images are `torch.tensors` of size $3\\times224\\times224$ and of type `torch.float` and that all labels are of type `int`.\n",
    "\n",
    "Note: the sanity check is only performed on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, t in testset:\n",
    "  assert isinstance(x, torch.Tensor)\n",
    "  assert isinstance(t, int)\n",
    "  assert x.shape==(3,224,224)\n",
    "  assert x.dtype==torch.float\n",
    "  assert x.max() < 3.0\n",
    "  assert x.min() > -3.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Feature Extraction\n",
    "\n",
    "We will use a pre-trained network available in `PyTorch`. \n",
    "Particularly, we will use a ResNet-50 architecture, but other architectures can also be tested. \n",
    "Fortunately, PyTorch provides simple interfaces to obtain pre-trained models, e.g., using the `torchvision.models.resnet50` interface function.\n",
    "\n",
    "In order to use the networks in a different dataset, we need to change their outputs. \n",
    "There are several possibilities on how to achieve that, and you have the freedom to choose. \n",
    "\n",
    "For your reference, the implementation of the `forward` function of ResNet networks (including ResNet-50) can be found here: https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py#L266\n",
    "\n",
    "You can also check if other networks perform better, for example, deeper ResNet topologies.\n",
    "Be aware that the strategy to replace the last fully-connected layer might not work the same way in other network topologies, only in residual networks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Pre-trained Network Instantiation\n",
    "\n",
    "Instantiate two pre-trained networks of type ResNet-50.\n",
    "\n",
    "1. Freeze the feature layers of the first network.\n",
    "\n",
    "Note: Make use the `old TorchVision Interface` to load your pre-trained network. Here is the link: https://pytorch.org/vision/0.12/models.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the first pre-trained resnet 50 network\n",
    "network_1 = ...\n",
    "# Make sure to freeze all the layers of the network.\n",
    "...\n",
    "\n",
    "# instantiate the second pre-trained resnet 50 network (optinally) without the freezing\n",
    "network_2 = ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Network Implementation\n",
    "\n",
    "We want to modify the network such that we extract the logits for the 6 classes from the last fully-connected layer of the network.\n",
    "\n",
    "Implement a function that:\n",
    "1. Replaces the current last linear layer of the pre-trained network with a new linear layer that has $O$ units ($O$ represents the number of classes in our dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_last_layer(network, O=6):\n",
    "  # replace the last linear layer with the new layer\n",
    "  ...\n",
    "\n",
    "  return network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Last layer dimensions\n",
    "\n",
    "This test ensures that the function return a network having the correct number of input and output units in the last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = 6\n",
    "for network in (network_1, network_2):\n",
    "    new_model = replace_last_layer(network, O=O)\n",
    "    assert new_model.fc.out_features == O\n",
    "    assert new_model.fc.in_features == 2048"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Training\n",
    "Implement a function that takes all necessary parameters to run a training on a given dataset. \n",
    "Select the optimizer to be `torch.optim.SGD` and `torch.nn.CrossEntropyLoss` as the loss function. \n",
    "The test set will be used as the validation set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Training and Evaluation Loop\n",
    "\n",
    "Implement a training loop over a specific number of epochs (5) with a learning rate of $\\eta=0.001$ and momentum of $\\mu = 0.9$. The function should return the predictions and the labels on the validation set after 5 epochs.\n",
    "\n",
    "In each loop, compute and print the training loss, training accuracy, validation loss and validation accuracy.\n",
    "\n",
    "Make sure that you train on the training data only, and `not` on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(...):\n",
    "    optimizer = torch.optim.SGD(...)\n",
    "    loss = ...\n",
    "\n",
    "    for epoch in range(...):\n",
    "\n",
    "        # training process\n",
    "        ...\n",
    "\n",
    "        # testing process\n",
    "        ...\n",
    "\n",
    "        # Calculate and print accuracies and losses for current epoch\n",
    "        ...\n",
    "\n",
    "    # Save predictions and target labels of the test set after the last epoch\n",
    "    pred, target = [], [] #Store only the test results\n",
    "    ...\n",
    "\n",
    "    return pred, target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Network Fine-Tuning with Frozen Layers\n",
    "\n",
    "Create a network that has feature layers frozen with $6$ output units. \n",
    "Fine-tune the created network on our Intel Image Classification data using the previous function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_with_frozen_layers = network_1\n",
    "pred_frozen, targ_frozen = train_eval(...)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7: Network Fine-Tuning without Frozen Layers \n",
    "\n",
    "Create a network from the second pre-trained network with $6$ output units. This network should not have the layers frozen.\n",
    "Fine-tune the created network on our dataset.\n",
    "\n",
    "Note:\n",
    "\n",
    "  * The fine-tuning of the network can take a long time (> 30 minutes) when the layers are not frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_normal = network_2 # Use network_2 defined above and replace the last layer\n",
    "pred_unfrozen, targ_frozen = train_eval(...)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "Finally, we want to plot the confusion matrix of the test set.\n",
    "For this, we need use the predictions and target values we saved from the previous tasks (Task 6 and Task 7).\n",
    "Finally, we can make use of the `sklearn.metrics.confusion_matrix` to compute the confusion matrix.\n",
    "You can utilize `sklearn.metrics.ConfusionMatrixDisplay` for displaying the confusion matrix, or `pyplot.imshow` and adding the according labels.\n",
    "\n",
    "Note:\n",
    "\n",
    "  * The documentation for the confusion matrix can be found here: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "  * The interface and an example for the `ConfusionMatrixDisplay` can be found here: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8: Confusion Matrix Plotting\n",
    "\n",
    "* Plot the confusion matrix for the fine-tuned network with frozen layers.\n",
    "* Also plot the confusion matrix for the second fine-tuned network without frozen layers. \n",
    "* Compare the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# add axis labels if required\n",
    "classes = trainset.classes\n",
    "\n",
    "# compute confusion matrix\n",
    "matrix_frozen = confusion_matrix(...) # Use predictions and target from the fine-tuned network with frozen layers\n",
    "matrix_unfrozen = confusion_matrix(...) # Use predictions and target from the fine-tuned network without frozen layers\n",
    "\n",
    "# plot confusion matrices\n",
    "plot_conf_matrix1 = ConfusionMatrixDisplay(..., display_labels=classes)\n",
    "plot_conf_matrix1.plot(xticks_rotation = \"vertical\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_conf_matrix2 = ConfusionMatrixDisplay(..., display_labels=classes)\n",
    "plot_conf_matrix1.plot(xticks_rotation = \"vertical\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2dd53f8ad749bca69f7250ce75eb4f0def59db5cf79075a9716322ffc58e8a2e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
